{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7390a61c-84f3-4aac-a367-7f9ef8c175f0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fbd559-ed0e-411f-8929-ae1688cf5413",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce097e3-ea48-466e-88a7-0a4260f416a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datadir_camembert = \"camembert-tokens.datasets\"\n",
    "datadir_flaubert = \"flaubert-tokens.datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda1dd1f-749e-4038-bed9-f0a97677b86b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_datasets_camembert = datasets.load_from_disk(datadir_camembert)\n",
    "tokenized_datasets_flaubert = datasets.load_from_disk(datadir_flaubert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5939e8b1-6ed2-4920-963d-7c616adab9d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset_camembert = tokenized_datasets_camembert[\"test\"].select(range(50))\n",
    "test_dataset_flaubert = tokenized_datasets_flaubert[\"test\"].select(range(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19365e31-a003-4a4b-8709-6a4abdeb5927",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd594715-f785-46aa-b754-60ea6dc95442",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_6800/507886441.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mFlaubertForSequenceClassification\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mCamembertForSequenceClassification\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# flaubert\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mmodel_name_fb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'./flaubert_base_cased_1'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/transformers/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;31m# and: https://github.com/tensorflow/tensorflow/issues/26691#issuecomment-500369493\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m     \u001B[0;32mimport\u001B[0m \u001B[0mabsl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogging\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m \u001B[0;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m     \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.7/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.7/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.7/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.7/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.7/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mget_code\u001B[0;34m(self, fullname)\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/nlp/lib/python3.7/importlib/_bootstrap_external.py\u001B[0m in \u001B[0;36mget_data\u001B[0;34m(self, path)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import FlaubertForSequenceClassification\n",
    "from transformers import CamembertForSequenceClassification\n",
    "\n",
    "# flaubert\n",
    "model_name_fb = './flaubert_base_cased_1'\n",
    "model_flaubert = FlaubertForSequenceClassification.from_pretrained(model_name_fb,\n",
    "                                                                   num_labels=2,\n",
    "                                                                   output_attentions=False,\n",
    "                                                                   output_hidden_states=True)\n",
    "\n",
    "# camembert\n",
    "model_name_cb = './camembert_base_1'\n",
    "model_camembert = CamembertForSequenceClassification.from_pretrained(model_name_cb,\n",
    "                                                                     num_labels=2,\n",
    "                                                                     output_attentions=False,\n",
    "                                                                     output_hidden_states=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb1a59-71be-459f-af05-288bc553af0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_flaubert.eval()\n",
    "model_camembert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533ccde-32f2-45b8-9d63-909dd01da168",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = test_dataset_flaubert[1]\n",
    "\n",
    "print(test.keys())\n",
    "output = model_flaubert(attention_mask=torch.tensor([test[\"attention_mask\"]]),\n",
    "                        input_ids=torch.tensor([test[\"input_ids\"]])\n",
    "                        )\n",
    "\n",
    "print(len(output.hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3e791-550d-4059-b048-6642e6fbd06f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = test_dataset_camembert[0]\n",
    "\n",
    "output = model_camembert(attention_mask=torch.tensor([test[\"attention_mask\"]]),\n",
    "                         input_ids=torch.tensor([test[\"input_ids\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917bf28-4f78-4928-a381-b7adfa09f127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(output.hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8285f1-9bb9-4f01-8fe1-3717b8b44826",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cosine study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe54bc9-5929-4805-860e-f2120b2204b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mat_sim(layer, attention_mask):\n",
    "    \"\"\"\n",
    "    :param layer: torch.tensor of the shape (1 (batch_size) , nb_tokens , 768)\n",
    "                  hidden states of the transformers\n",
    "    :param attention_mask: torch.tensor of the shape (1, nb_tokens)\n",
    "\n",
    "    :return: res : the similarity matrix of the shape (k,k)\n",
    "             k   : the numer of non-pad tokens in the sentence we are dealing with\n",
    "    \"\"\"\n",
    "\n",
    "    # with the dataset we are nb_token = 512\n",
    "    nb_token = layer.shape[1]\n",
    "\n",
    "    l = []\n",
    "    k = 0\n",
    "    for i in range(nb_token):\n",
    "        if attention_mask[i] == 1:\n",
    "            '''\n",
    "            check of the padding\n",
    "            '''\n",
    "            l.append(list(layer[0, i, :].detach().numpy()))\n",
    "            k += 1\n",
    "        else:\n",
    "            '''\n",
    "            stop the loop\n",
    "            '''\n",
    "            break\n",
    "\n",
    "    l = np.array(l).T\n",
    "\n",
    "    res = np.zeros((k, k))\n",
    "\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            # cosine calculus\n",
    "            res[i, j] = np.dot(l[:, i], l[:, j]) / (np.linalg.norm(l[:, i]) * np.linalg.norm(l[:, j]))\n",
    "\n",
    "    return res, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b89786-e06d-41ab-b1d7-10ba9f94089f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def construct_df_dist(datasets,\n",
    "                      type_model: str = \"flaubert\"):\n",
    "    \"\"\"\n",
    "    :param datasets: one of the tokenized dataset (FlauBERT or CamemBERT)\n",
    "    :param type_model: choose between FlauBERT or CamemBERT\n",
    "\n",
    "    :return: df_dist : - a dataframe with 13 columns.\n",
    "                       - on each columns corresponds to a layer in the transformer a nd\n",
    "                         the values corresponds to the cosine similarities within each sentences\n",
    "\n",
    "             df_var : - a dataframe with 13 columns\n",
    "                      - on each columns corresponds to a layer in the transformer and\n",
    "                        each value corresponds to the variance of the values of the cosine similarity within each layer\n",
    "    \"\"\"\n",
    "\n",
    "    nb_layer = 13\n",
    "\n",
    "    mat_var = {}\n",
    "\n",
    "    mat_dist = {}\n",
    "\n",
    "    for i in range(nb_layer):\n",
    "        mat_dist[i] = []\n",
    "        mat_var[i] = []\n",
    "\n",
    "    for data in datasets:\n",
    "\n",
    "        # store the output\n",
    "        output = None\n",
    "\n",
    "        if type_model == \"flaubert\":\n",
    "            output = model_flaubert(attention_mask=torch.tensor([data[\"attention_mask\"]]),\n",
    "                                    input_ids=torch.tensor([data[\"input_ids\"]])\n",
    "                                    )\n",
    "        else:\n",
    "            output = model_camembert(attention_mask=torch.tensor([data[\"attention_mask\"]]),\n",
    "                                     input_ids=torch.tensor([data[\"input_ids\"]]))\n",
    "\n",
    "        # we store the hidden_states\n",
    "        hidden_states = output.hidden_states\n",
    "\n",
    "        for i in range(nb_layer):\n",
    "            curr_layer = hidden_states[i]\n",
    "            mat_cos, n = mat_sim(curr_layer, data[\"attention_mask\"])  # cosine matrice\n",
    "\n",
    "            l = list(mat_cos[np.triu_indices(n, k=1)])\n",
    "\n",
    "            mat_var[i].append(np.var(l))\n",
    "            mat_dist[i] += l\n",
    "\n",
    "    df_var = pd.DataFrame(mat_var)\n",
    "    df_dist = pd.DataFrame(mat_dist)\n",
    "\n",
    "    new_col = ['layer' + \"_\" + str(i) for i in df_var.columns]\n",
    "\n",
    "    d = dict(zip(df_var.columns, new_col))\n",
    "\n",
    "    df_var.rename(columns=d,\n",
    "                  inplace=True)\n",
    "\n",
    "    df_dist.rename(columns=d,\n",
    "                   inplace=True)\n",
    "\n",
    "    return df_dist, df_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d7a95-d1b6-40ca-a13e-2404a180a22f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def df_cos(df_dist):\n",
    "    \"\"\"\n",
    "    :param df_dist: the df_dist we return on the previous function.\n",
    "    :return: a dataframe with the good format for a plot with legend on seaborn\n",
    "    \"\"\"\n",
    "    dist_vect = []\n",
    "    legend_vect = []\n",
    "\n",
    "    for column in df_dist:\n",
    "        dist_vect += list(df_dist[column].values)\n",
    "        legend_vect += [column] * len(df_dist[column])\n",
    "\n",
    "    df = pd.DataFrame({\"layer\": legend_vect, \"cosines\": dist_vect})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361a1db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d470b73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "# work on flaubert\n",
    "df_dist, df_var = construct_df_dist(test_dataset_flaubert)\n",
    "cos_values = df_cos(df_dist)\n",
    "fig = sns.boxplot(x=\"layer\", y=\"cosines\", data=cos_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb18d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# work on camembert\n",
    "df_dist, df_var = construct_df_dist(test_dataset_camembert, type_model=\"camembert\")\n",
    "cos_values = df_cos(df_dist)\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "fig = sns.boxplot(x=\"layer\", y=\"cosines\", data=cos_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b75d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Vcov study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760893e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cov_emb(layer, attention_mask):\n",
    "    \"\"\"\n",
    "    :param layer: torch.tensor of the shape (1 (batch_size) , nb_tokens , 768)\n",
    "                  hidden states of the transformers\n",
    "    :param attention_mask: torch.tensor of the shape (1, nb_tokens)\n",
    "\n",
    "    :return: the vcov matrix of the embeddings, on the layer\n",
    "    \"\"\"\n",
    "    nb_tok = layer.shape[1]\n",
    "\n",
    "    l = []\n",
    "\n",
    "    for i in range(nb_tok):\n",
    "        if attention_mask[i] == 1:\n",
    "            l.append(list(layer[0, i, :].detach().numpy()))\n",
    "        else:\n",
    "            # if we encounter a padding all the rest is padding\n",
    "            break\n",
    "\n",
    "    l = np.array(l).T\n",
    "\n",
    "    return (np.cov(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8232fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def df_trace_vcov(dataset,\n",
    "                  type_model: str = \"flaubert\",\n",
    "                  nb_layer: int = 13):\n",
    "    \"\"\"\n",
    "    :param dataset: one of the dataset provided\n",
    "    :param type_model: choose between FlauBERT or CamemBERT\n",
    "    :param nb_layer: the number of layer in the model we want to use\n",
    "                     (this parameter is a bit useless considering both models have 13 layers)\n",
    "\n",
    "    :return: df: a pandas dataframe with nb_layer columns each columns corresponding to a layer of the model\n",
    "                 the values within each columns correspond to the trace of the vcov (calculated above) for different layer\n",
    "    \"\"\"\n",
    "    legend_vect = []\n",
    "    trace_vect = []\n",
    "\n",
    "    for data in dataset:\n",
    "        output = None\n",
    "\n",
    "        # output of the model\n",
    "        if type_model == \"flaubert\":\n",
    "            output = model_flaubert(attention_mask=torch.tensor([data[\"attention_mask\"]]),\n",
    "                                    input_ids=torch.tensor([data[\"input_ids\"]])\n",
    "                                    )\n",
    "        else:\n",
    "            output = model_camembert(attention_mask=torch.tensor([data[\"attention_mask\"]]),\n",
    "                                     input_ids=torch.tensor([data[\"input_ids\"]]))\n",
    "\n",
    "        # hidden_states of the transformers\n",
    "        hidden_states = output.hidden_states\n",
    "\n",
    "        for i in range(nb_layer):\n",
    "            curr_layer = hidden_states[i]\n",
    "            lay = \"layer_\" + str(i + 1)\n",
    "            buff = np.trace(cov_emb(curr_layer, data[\"attention_mask\"]))\n",
    "            legend_vect.append(lay)\n",
    "            trace_vect.append(buff)\n",
    "\n",
    "    df = pd.DataFrame({\"layer\": legend_vect,\n",
    "                       \"trace\": trace_vect})\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aebf38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset_camembert = tokenized_datasets_camembert[\"test\"].select(range(100))\n",
    "test_dataset_flaubert = tokenized_datasets_flaubert[\"test\"].select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d599eee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# work on flaubert\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "df = df_trace_vcov(test_dataset_flaubert)\n",
    "fig = sns.boxplot(x=\"layer\", y=\"trace\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de353013",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# work on camembert\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "df = df_trace_vcov(test_dataset_camembert, type_model=\"camembert\")\n",
    "fig = sns.boxplot(x=\"layer\", y=\"trace\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6734e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Erank study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64713ea7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def erank_metric(W):\n",
    "    #   --> we assume that nrow(W) > ncol(W)\n",
    "    #   --> decomposition of the matrix in singular value\n",
    "    u, s, vh = np.linalg.svd(W, full_matrices=True)\n",
    "    #   s --> singular values of the matrix W\n",
    "\n",
    "    s1 = np.sum(s)  # sum of the singular values\n",
    "\n",
    "    k = s / s1\n",
    "    k = k * np.log(k)\n",
    "\n",
    "    return (np.exp(-sum(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeabebd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculus_erank(dataset,\n",
    "                   type_model: str = \"flaubert\",\n",
    "                   nb_tok: int = 512):\n",
    "    \"\"\"\n",
    "    :param nb_tok: number of tokens on each sentence (padded sentences)\n",
    "    :return: pandas dataframe of the values of erank on each layer\n",
    "             calculated on multiple sentences\n",
    "    \"\"\"\n",
    "    layer_W = {}\n",
    "\n",
    "    for i in range(13):\n",
    "        layer_W[i + 1] = []\n",
    "\n",
    "    for data in dataset:\n",
    "        output = None\n",
    "\n",
    "        # output of the model\n",
    "        if type_model == \"flaubert\":\n",
    "            output = model_flaubert(attention_mask=torch.tensor([data[\"attention_mask\"]]),\n",
    "                                    input_ids=torch.tensor([data[\"input_ids\"]])\n",
    "                                    )\n",
    "        else:\n",
    "            output = model_camembert(attention_mask=torch.tensor([data[\"attention_mask\"]]),\n",
    "                                     input_ids=torch.tensor([data[\"input_ids\"]]))\n",
    "\n",
    "        # hidden_states of the transformers\n",
    "        hidden_states = output.hidden_states\n",
    "\n",
    "        for i in range(13):\n",
    "            curr_layer = hidden_states[i][0]  #   --> current layer.\n",
    "\n",
    "            for t in range(nb_tok):\n",
    "                if data[\"attention_mask\"][t] == 1:\n",
    "                    emb_tok = list(curr_layer[t, :].detach().numpy())\n",
    "                    layer_W[i + 1].append(emb_tok)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    d = {\"erank\": [], \"layer\": []}\n",
    "    for i in range(13):\n",
    "        d[\"erank\"].append(erank_metric(np.array(layer_W[i + 1])))\n",
    "        d[\"layer\"].append(\"layer_\" + str(i + 1))\n",
    "\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bda1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset_camembert = tokenized_datasets_camembert[\"test\"].select(range(10))\n",
    "test_dataset_flaubert = tokenized_datasets_flaubert[\"test\"].select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca055a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(20, 10))\n",
    "df = calculus_erank(dataset=test_dataset_flaubert, type_model=\"flaubert\")\n",
    "sns.barplot(x=\"layer\", y=\"erank\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44110519-c7f8-4c1c-8679-9a32042424fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09761858",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = calculus_erank(dataset=test_dataset_camembert, type_model=\"camembert\")\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"layer\", y=\"erank\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709d0d1-11c5-4172-b6e8-cf58f32e5bec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}